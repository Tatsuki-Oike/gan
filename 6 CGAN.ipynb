{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE5GXEzgn-p1"
   },
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1612066217951,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "MLyQpZLTse-n",
    "outputId": "c5bb9ca4-6df4-47c1-ff67-04342e7638a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 31 04:10:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4470,
     "status": "ok",
     "timestamp": 1612066237288,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "4JSI-ob1LXJ3",
    "outputId": "f21ba36c-8a85-40fc-8028-a6fec39c3df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu101\n",
      "0.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "# バージョン指定時にコメントアウト\n",
    "#!pip install torch==1.7.0\n",
    "#!pip install torchvision==0.8.1\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "# バージョンの確認\n",
    "print(torch.__version__) \n",
    "print(torchvision.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24418,
     "status": "ok",
     "timestamp": 1612066272320,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "VGlfMTUfa-It",
    "outputId": "70f3b734-3044-4072-cd22-a2af6afcc96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Google ドライブにマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1612066276177,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "GpXhG3lzbSBK",
    "outputId": "decbabde-38bd-49ee-ec39-ba23d5a7f185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/Colab Notebooks/gan_sample/chapter3\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/gdrive/MyDrive/Colab Notebooks/gan_sample/chapter3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfdH0jXxC-pk"
   },
   "outputs": [],
   "source": [
    "# パッケージのインポート\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1612066303003,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "UAp9p1iOC-pp",
    "outputId": "8b9f79fd-e5f5-44e7-8154-2307a0d5d409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efedc26cbd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定\n",
    "workers = 2\n",
    "batch_size=50\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 10\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './result_3_3-CGAN'\n",
    "display_interval = 600\n",
    "\n",
    "# 保存先ディレクトリを作成\n",
    "try:\n",
    "    os.makedirs(outf, exist_ok=True)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "# 乱数のシード（種）を固定\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usD6N-1Wo6NW"
   },
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETttQCP4y30H"
   },
   "outputs": [],
   "source": [
    "# MNISTの訓練データセットを読み込む\n",
    "dataset = dset.MNIST(root='./mnist_root', download=True, train=True,\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5,), (0.5,)) ])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1612066315241,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "Wvn5iRLX2aJ-",
    "outputId": "e6c2a934-f8e7-45ac-be05-7cc4c5548bfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 画像配列の確認\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1612066317341,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "aVJAuz2r0UH1",
    "outputId": "9cd36f0d-cce6-4ba1-81e8-c3008e63cac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=int(workers))\n",
    "\n",
    "# 学習に使用するデバイスを得る。可能ならGPUを使用する\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3rruPyko-8r"
   },
   "source": [
    "# ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmsd_MKAlXw6"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    生成器Gのクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, nz=100, nch_g=64, nch=1):\n",
    "        \"\"\"\n",
    "        :param nz: 入力ベクトルzの次元\n",
    "        :param nch_g: 最終層の入力チャネル数\n",
    "        :param nch: 出力画像のチャネル数\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # ニューラルネットワークの構造を定義する\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'layer0': nn.Sequential(\n",
    "                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),     # 転置畳み込み\n",
    "                nn.BatchNorm2d(nch_g * 4),                      # バッチノーマライゼーション\n",
    "                nn.ReLU()                                       # ReLU\n",
    "            ),  # (B, nz, 1, 1) -> (B, nch_g*4, 3, 3)\n",
    "            'layer1': nn.Sequential(\n",
    "                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_g * 2),\n",
    "                nn.ReLU()\n",
    "            ),  # (B, nch_g*4, 3, 3) -> (B, nch_g*2, 7, 7)\n",
    "            'layer2': nn.Sequential(\n",
    "                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_g),\n",
    "                nn.ReLU()\n",
    "            ),  # (B, nch_g*2, 7, 7) -> (B, nch_g, 14, 14)\n",
    "            'layer3': nn.Sequential(\n",
    "                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n",
    "                nn.Tanh()\n",
    "            )   # (B, nch_g, 14, 14) -> (B, nch, 28, 28)\n",
    "        })\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        順方向の演算\n",
    "        :param z: 入力ベクトル\n",
    "        :return: 生成画像\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():  # self.layersの各層で演算を行う\n",
    "            z = layer(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTK-Mvf2ldoI"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    識別器Dのクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, nch=1, nch_d=64):\n",
    "        \"\"\"\n",
    "        :param nch: 入力画像のチャネル数\n",
    "        :param nch_d: 先頭層の出力チャネル数\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # ニューラルネットワークの構造を定義する\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'layer0': nn.Sequential(\n",
    "                nn.Conv2d(nch, nch_d, 4, 2, 1),     # 畳み込み\n",
    "                nn.LeakyReLU(negative_slope=0.2)    # leaky ReLU関数\n",
    "            ),  # (B, nch, 28, 28) -> (B, nch_d, 14, 14)\n",
    "            'layer1': nn.Sequential(\n",
    "                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nch_d * 2),\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),  # (B, nch_d, 14, 14) -> (B, nch_d*2, 7, 7)\n",
    "            'layer2': nn.Sequential(\n",
    "                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n",
    "                nn.BatchNorm2d(nch_d * 4),\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),  # (B, nch_d*2, 7, 7) -> (B, nch_d*4, 3, 3)\n",
    "            'layer3': nn.Sequential(\n",
    "                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n",
    "                nn.Sigmoid()\n",
    "            )    \n",
    "            # (B, nch_d*4, 3, 3) -> (B, 1, 1, 1)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順方向の演算\n",
    "        :param x: 本物画像あるいは生成画像\n",
    "        :return: 識別信号\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():  # self.layersの各層で演算を行う\n",
    "            x = layer(x)\n",
    "        return x.squeeze()     # Tensorの形状を(B)に変更して戻り値とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkuriTFqlMfq"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    ニューラルネットワークの重みを初期化する。作成したインスタンスに対しapplyメソッドで適用する\n",
    "    :param m: ニューラルネットワークを構成する層\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:            # 畳み込み層の場合\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:        # 全結合層の場合\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('BatchNorm') != -1:     # バッチノーマライゼーションの場合\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11161,
     "status": "ok",
     "timestamp": 1612066331462,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "BHW7ebSqtc1K",
    "outputId": "64a512b2-ab19-4694-8c99-3a1bde65fe02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): ConvTranspose2d(110, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 生成器G。ランダムベクトルから生成画像を作成する\n",
    "netG = Generator(nz=nz+10, nch_g=nch_g).to(device) #10はn_class=10を指す。出し分けに必要なラベル情報\n",
    "netG.apply(weights_init)    # weights_init関数で初期化\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1612066352779,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "jVxTCM5sEuED",
    "outputId": "f313c86b-d8bd-4ae8-8de2-fae355006b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 3, 3]         507,392\n",
      "       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-3            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n",
      "       BatchNorm2d-8          [-1, 128, 14, 14]             256\n",
      "              ReLU-9          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,215,553\n",
      "Trainable params: 2,215,553\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 8.45\n",
      "Estimated Total Size (MB): 9.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 生成器GのTensor形状\n",
    "torchsummary.summary(netG, (110, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1612066356045,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "rriIYwAFC-pz",
    "outputId": "08b110f1-93dc-41de-ad8e-1019b17deea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): Conv2d(11, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 識別器D。画像が本物か生成かを識別する\n",
    "netD = Discriminator(nch=1+10, nch_d=nch_d).to(device) #10はn_class=10を指す。分類に必要なラベル情報\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1612066358400,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "4_PWX2WGFRqb",
    "outputId": "aec0671a-9491-4929-8be0-1cb21b77655b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]          22,656\n",
      "         LeakyReLU-2          [-1, 128, 14, 14]               0\n",
      "            Conv2d-3            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 7, 7]             512\n",
      "         LeakyReLU-5            [-1, 256, 7, 7]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,733,505\n",
      "Trainable params: 1,733,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 6.61\n",
      "Estimated Total Size (MB): 7.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 識別器DのTensor形状\n",
    "torchsummary.summary(netD, (11, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbheRXWwpIn-"
   },
   "source": [
    "# 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjfl5HxRC-p1"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()    # バイナリークロスエントロピー（Sigmoid関数無し）\n",
    "\n",
    "# オプティマイザ−のセットアップ\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RkjI57KDyc5"
   },
   "outputs": [],
   "source": [
    "def onehot_encode(label, device, n_class=10):\n",
    "    \"\"\"\n",
    "    カテゴリカル変数のラベルをOne-Hoe形式に変換する\n",
    "    :param label: 変換対象のラベル\n",
    "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
    "    :param n_class: ラベルのクラス数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eye = torch.eye(n_class, device=device)\n",
    "    # ランダムベクトルあるいは画像と連結するために(B, c_class, 1, 1)のTensorにして戻す\n",
    "    return eye[label].view(-1, n_class, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av1H0Fo-D0UL"
   },
   "outputs": [],
   "source": [
    "def concat_image_label(image, label, device, n_class=10):\n",
    "    \"\"\"\n",
    "    画像とラベルを連結する\n",
    "    :param image:　画像\n",
    "    :param label: ラベル\n",
    "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
    "    :param n_class: ラベルのクラス数\n",
    "    :return:　画像とラベルをチャネル方向に連結したTensor\n",
    "    \"\"\"\n",
    "    B, C, H, W = image.shape    # 画像Tensorの大きさを取得\n",
    "    \n",
    "    oh_label = onehot_encode(label, device)         # ラベルをOne-Hotベクトル化\n",
    "    oh_label = oh_label.expand(B, n_class, H, W)    # 画像のサイズに合わせるようラベルを拡張する\n",
    "    return torch.cat((image, oh_label), dim=1)      # 画像とラベルをチャネル方向（dim=1）で連結する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S5mqSttD0hj"
   },
   "outputs": [],
   "source": [
    "def concat_noise_label(noise, label, device):\n",
    "    \"\"\"\n",
    "    ノイズ（ランダムベクトル）とラベルを連結する\n",
    "    :param noise: ノイズ\n",
    "    :param label: ラベル\n",
    "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
    "    :return:　ノイズとラベルを連結したTensor\n",
    "    \"\"\"\n",
    "    oh_label = onehot_encode(label, device)     # ラベルをOne-Hotベクトル化\n",
    "    return torch.cat((noise, oh_label), dim=1)  # ノイズとラベルをチャネル方向（dim=1）で連結する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1612066398646,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "3pSpplj6EhjN",
    "outputId": "af053533-1ee9-41c9-b242-d8d64e4e2ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 1, 1])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0')\n",
      "torch.Size([50, 110, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# 生成器のエポックごとの画像生成に使用する確認用の固定ノイズ\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device) \n",
    "# 確認用のラベル。0〜9のラベルの繰り返し\n",
    "fixed_label = [i for i in range(10)] * (batch_size // 10)\n",
    "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
    "# 確認用のノイズとラベルを連結\n",
    "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device) \n",
    "print(fixed_noise.shape)\n",
    "print(fixed_label)\n",
    "print(fixed_noise_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 589037,
     "status": "ok",
     "timestamp": 1612067046791,
     "user": {
      "displayName": "毛利拓也",
      "photoUrl": "",
      "userId": "17854120745961292401"
     },
     "user_tz": -540
    },
    "id": "lckGpHvMC-p5",
    "outputId": "1704506e-103f-43a5-ed00-60dacf02417e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10][1/1200] Loss_D: 1.743 Loss_G: 1.737 D(x): 0.636 D(G(z)): 0.683/0.208\n",
      "[1/10][601/1200] Loss_D: 0.849 Loss_G: 1.176 D(x): 0.633 D(G(z)): 0.237/0.367\n",
      "[2/10][1/1200] Loss_D: 0.859 Loss_G: 2.031 D(x): 0.789 D(G(z)): 0.401/0.159\n",
      "[2/10][601/1200] Loss_D: 1.447 Loss_G: 1.654 D(x): 0.671 D(G(z)): 0.585/0.225\n",
      "[3/10][1/1200] Loss_D: 1.278 Loss_G: 1.289 D(x): 0.586 D(G(z)): 0.470/0.306\n",
      "[3/10][601/1200] Loss_D: 1.032 Loss_G: 1.219 D(x): 0.608 D(G(z)): 0.363/0.328\n",
      "[4/10][1/1200] Loss_D: 1.041 Loss_G: 1.713 D(x): 0.701 D(G(z)): 0.466/0.199\n",
      "[4/10][601/1200] Loss_D: 0.699 Loss_G: 1.833 D(x): 0.845 D(G(z)): 0.380/0.186\n",
      "[5/10][1/1200] Loss_D: 1.633 Loss_G: 0.617 D(x): 0.337 D(G(z)): 0.327/0.558\n",
      "[5/10][601/1200] Loss_D: 0.779 Loss_G: 1.522 D(x): 0.601 D(G(z)): 0.205/0.236\n",
      "[6/10][1/1200] Loss_D: 1.378 Loss_G: 1.598 D(x): 0.397 D(G(z)): 0.297/0.233\n",
      "[6/10][601/1200] Loss_D: 0.794 Loss_G: 1.366 D(x): 0.601 D(G(z)): 0.212/0.282\n",
      "[7/10][1/1200] Loss_D: 1.308 Loss_G: 1.459 D(x): 0.728 D(G(z)): 0.582/0.260\n",
      "[7/10][601/1200] Loss_D: 1.118 Loss_G: 1.193 D(x): 0.496 D(G(z)): 0.289/0.326\n",
      "[8/10][1/1200] Loss_D: 1.299 Loss_G: 1.406 D(x): 0.668 D(G(z)): 0.546/0.272\n",
      "[8/10][601/1200] Loss_D: 1.070 Loss_G: 1.604 D(x): 0.693 D(G(z)): 0.469/0.221\n",
      "[9/10][1/1200] Loss_D: 1.710 Loss_G: 0.706 D(x): 0.267 D(G(z)): 0.232/0.521\n",
      "[9/10][601/1200] Loss_D: 1.039 Loss_G: 1.059 D(x): 0.537 D(G(z)): 0.299/0.371\n",
      "[10/10][1/1200] Loss_D: 1.245 Loss_G: 1.221 D(x): 0.498 D(G(z)): 0.355/0.320\n",
      "[10/10][601/1200] Loss_D: 0.948 Loss_G: 1.400 D(x): 0.555 D(G(z)): 0.245/0.273\n"
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        real_image = data[0].to(device)     # 本物画像\n",
    "        real_label = data[1].to(device)     # 本物画像に対応するラベル\n",
    "        # 本物画像とラベルを連結\n",
    "        real_image_label = concat_image_label(real_image, real_label, device) \n",
    "        sample_size = real_image.size(0)    # 画像枚数\n",
    "\n",
    "        # 標準正規分布からノイズを生成\n",
    "        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n",
    "        # 生成画像生成用のラベル\n",
    "        fake_label = torch.randint(10, (sample_size,), dtype=torch.long, device=device)\n",
    "        # ノイズとラベルを連結\n",
    "        fake_noise_label = concat_noise_label(noise, fake_label, device)        \n",
    "        # 本物画像に対する識別信号の目標値「1」\n",
    "        real_target = torch.full((sample_size,), 1., device=device)\n",
    "        # 生成画像に対する識別信号の目標値「0」\n",
    "        fake_target = torch.full((sample_size,), 0., device=device)\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        netD.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        # 識別器Dで本物画像とラベルの組み合わせに対する識別信号を出力\n",
    "        output = netD(real_image_label)\n",
    "        # 本物画像に対する識別信号の損失値\n",
    "        errD_real = criterion(output, real_target)\n",
    "\n",
    "        D_x = output.mean().item()  # 本物画像の識別信号の平均\n",
    "\n",
    "        fake_image = netG(fake_noise_label)  # 生成器Gでラベルに対応した生成画像を生成\n",
    "        # 生成画像とラベルを連結\n",
    "        fake_image_label = concat_image_label(fake_image, fake_label, device)   \n",
    "        \n",
    "        # 識別器Dで本物画像に対する識別信号を出力\n",
    "        output = netD(fake_image_label.detach()) \n",
    "        # 生成画像に対する識別信号の損失値\n",
    "        errD_fake = criterion(output, fake_target)  \n",
    "        D_G_z1 = output.mean().item()# 生成画像の識別信号の平均\n",
    "\n",
    "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
    "        errD.backward()    # 誤差逆伝播\n",
    "        optimizerD.step()   # Dのパラメーターを更新\n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        netG.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        output = netD(fake_image_label)     # 更新した識別器Dで改めて生成画像とラベルの組み合わせに対する識別信号を出力\n",
    "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに生成画像を本物画像と誤認させたいため目標値は「1」\n",
    "        errG.backward()     # 誤差逆伝播\n",
    "        D_G_z2 = output.mean().item()# 更新した識別器Dによる生成画像の識別信号の平均\n",
    "\n",
    "        optimizerG.step()   # Gのパラメータを更新\n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloader),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0:     # 初回に本物画像を保存する\n",
    "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用画像の生成\n",
    "    ############################\n",
    "    fake_image = netG(fixed_noise_label)  # 1エポック終了ごとに確認用の生成画像を生成する\n",
    "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "                      normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # モデルの保存\n",
    "    ############################\n",
    "    if (epoch + 1) % 10 == 0:   # 10エポックごとにモデルを保存する\n",
    "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "section3_3-CGAN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
